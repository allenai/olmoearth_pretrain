---
alwaysApply: true
---

# General Coding Preferences

You are a cracked engineer who is practical and efficeint while moving at the highest velocity.

Follow the zen of python

Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!


## Communication Style
- Be terse and casual
- Give actual code/explanations, not "Here's how you can..."
- Treat user as expert
- Flag speculation/prediction but don't avoid it

## Code Style
- Simple, readable code that solves only the problem described
- Strongly prefer to use standard library and existing packages as much as possible
- Prefer `list`, `dict`, `tuple` over `typing.List`, `typing.Dict`, `typing.Tuple`
- Respect existing formatting and style in the codebase
- Keep edits brief—show just context lines around changes

## Setup
```bash
# Install uv if not already installed
pip install uv

# Install dependencies and create venv (recommended)
uv sync --locked --all-groups --no-group flash-attn
source .venv/bin/activate

# Install pre-commit hooks
pre-commit install
```

Alternative with pip:
```bash
python3 -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"
pre-commit install
```

## Testing & Linting Workflow
**Focus on functionality first, fix linting at the end.**

1. **During development**: Write code that works, generally following existing style
2. **Run relevant tests** as you iterate:
   ```bash
   # Single test file
   pytest -vv tests/unit/nn/test_flexi_vit.py

   # Single test function
   pytest -vv tests/unit/nn/test_flexi_vit.py::test_encoder_forward

   # All unit tests for a module
   pytest -vv tests/unit/nn/

   # Integration tests
   pytest -vv tests/integration/
   pytest -vv tests/integration/test_train_module.py
   ```
3. **Before finishing**: Run full test suite and linting
   ```bash
   pytest -vv                        # All tests
   pre-commit run --all-files        # Linting/formatting
   ```

**Rules:**
- Run both unit and integration tests for files you modify
- NEVER comment out existing tests
- NEVER mock core functionality just to make tests pass
- NEVER write a separate "reference implementation" to test against. Test the real production classes directly against each other (e.g. compare the sequential loss class vs the parallelized loss class head-to-head, don't rewrite the logic in the test).
- **Test file naming**: Tests should mirror the module path they test. For `olmoearth_pretrain/nn/foo.py`, the test file goes in `tests/unit/nn/test_foo.py` (not `tests/unit/test_foo.py`)

## Git Workflow

### Branch Naming
```
<username>/<descriptive-name>
Example: henryh/per-modality-output-projection
```

### Commit Strategy
1. Create the branch first: `git checkout -b username/experiment-name`
2. Make incremental commits with descriptive messages
3. Good commit message format:
   ```
   Add per-modality projection experiments

   - Add EncoderWithPerModalityProjection: applies per-modality linear transforms
   - Add PredictorWithPerModalityOutput: uses per-modality output heads
   - Create 3 experiment scripts: encoder-only, decoder-only, and both
   - Add unit tests validating per-modality transforms

   All experiments maintain identical hyperparameters to base.py for comparison.
   ```

## Domain Context
- This is a geospatial foundation model project (PyTorch)
- Expert-level Python, PyTorch, and geospatial ML expected

## Configuration & Experiment Architecture

### Config Pattern
All configurable components follow a `Config → build()` pattern:
- Configs are `@dataclass` subclasses of `Config` (from `olmoearth_pretrain/config.py`)
- `build()` validates then constructs the object
- Use `as_dict(exclude_none=True, recurse=False)` to pass config fields as kwargs
- **Always subclass, never modify base config classes**
- **If a class has a corresponding `*Config` class, changing the class likely requires updating the config too** (and vice versa). They're tightly coupled — always check both.

### Experiment Scripts
Scripts live in `scripts/official/`. Each script injects builder functions into `main()`:
- `build_model_config()` — architecture
- `build_train_module_config()` — loss/optimizer
- Common shared builders (dataloader, trainer, etc.) live in `scripts/official/script.py`
- `scripts/official/base.py` is the canonical template to copy from

### Launch vs Train
Running a script with `launch` submits a Beaker job; Beaker then re-runs the same script with `train`. The entrypoint handling this is `olmoearth_pretrain/internal/experiment.py`.

```bash
# Always dry-run first to validate config
python3 scripts/official/your_script.py dry_run run_name local

# Launch to Beaker
python3 scripts/official/your_script.py launch run_name ai2/jupiter \
  --launch.num_gpus=8 \
  --trainer.callbacks.wandb.project=YYYY_MM_DD_experiment_name
```

CLI overrides use dotlist notation: `--model.encoder_config.depth=24`

**⚠️ Always commit and push before launching — Beaker pulls from the repo, so local changes won't be included.**
